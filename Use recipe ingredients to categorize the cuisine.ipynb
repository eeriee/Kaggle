{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Name:** WANG XI\n",
    "\n",
    "**EID:** xwang258\n",
    "\n",
    "**Name:** Yu Mingjie\n",
    "\n",
    "**EID:** mingjieyu2\n",
    "\n",
    "**Kaggle Competition:** What's cooking?\n",
    "\n",
    "**Kaggle Team Name:** Group2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS4487 - Course Project\n",
    "Due date: Nov 27, 2015 11:59pm HKT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goal\n",
    "You can select your course project as _one_ of the following Kaggle competitions:\n",
    "  1. [What's cooking?](https://www.kaggle.com/c/whats-cooking) - cooking ingredients to classify the type of cuisine.\n",
    "  2. [Trip type classification](https://www.kaggle.com/c/walmart-recruiting-trip-type-classification) - from a shopping list, predict the what type of shopping trip the customer is on (e.g., weekly groceries, clothes shopping).\n",
    "\n",
    "## Groups\n",
    "Group projects with at most 2 students are allowed.  To sign up for a group, go to Canvas and under \"People\", join one of the existing \"Project Groups\".  _For group projects, the project report must state the percentage contribution from each project member._\n",
    "\n",
    "## Methodology\n",
    "You are free to choose the methodology to solve the task.  In machine learning, it is important to use domain knowledge to help solve the problem.  Hence, instead of blindly applying the algorithms to the data you need to think about how to represent the data in a way that makes sense for the algorithm to solve the task. \n",
    "\n",
    "\n",
    "## Evaluation on Kaggle\n",
    "\n",
    "Besides evaluating on the validation set, you need to submit your test results to Kaggle for evaluation.\n",
    "\n",
    "## Project Presentation\n",
    "\n",
    "Each project group needs to give a presentation at the end of the semester.  The presentation time is 10 minutes.  You _must_ give a presentation.\n",
    "\n",
    "## What to hand in\n",
    "You need to turn in the following things:\n",
    "\n",
    "1. This ipynb file with your source code and documentation.\n",
    "2. Your final submission file to Kaggle.\n",
    "3. Presentation slides.\n",
    "\n",
    "Files should be uploaded to \"Course Project\" on Canvas.\n",
    "\n",
    "\n",
    "## Grading\n",
    "The marks of the assignment are distributed as follows:\n",
    "- 50% - Results using various feature representations, dimensionality reduction methods, classifiers, etc.\n",
    "- 20% - Trying out feature representations (e.g. adding additional features, combining features from different sources) or methods not used in the tutorials.\n",
    "- 15% - Quality of the written report.  More points for insightful observations and analysis.\n",
    "- 15% - Project presentation.\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Contribution from each project member: WANG XI 50% and Yu Mingjie 50%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import IPython.core.display         \n",
    "# setup output image format (Chrome works best)\n",
    "IPython.core.display.set_matplotlib_formats(\"svg\")\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "from numpy import *\n",
    "from sklearn import *\n",
    "from scipy import stats\n",
    "import IPython.utils.warn as warn\n",
    "random.seed(100)\n",
    "import json\n",
    "import csv\n",
    "import time\n",
    "import nltk\n",
    "from nltk import word_tokenize   \n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_cooking(fname):\n",
    "    # load the cooking dataset\n",
    "    # returns dictionary with data, target (cuisine type), item ids\n",
    "    \n",
    "    fp = open(fname, \"r\")\n",
    "    dataj = json.load(fp)\n",
    "    fp.close()\n",
    "    \n",
    "    data = []\n",
    "    ids  = []\n",
    "    target = []\n",
    "    for o in dataj:\n",
    "        if o.has_key('cuisine'):\n",
    "            target.append(o['cuisine'])\n",
    "        ids.append(o['id'])\n",
    "        data.append(o['ingredients'])\n",
    "\n",
    "    out = {\"data\": data, \"id\":ids}\n",
    "    if len(target) > 0:\n",
    "        out[\"target\"] =  target\n",
    "    return out\n",
    "\n",
    "\n",
    "# write a kaggle submission file for \"whats cooking\"\n",
    "def write_csv_kaggle_cooking(fname, ids, target):\n",
    "    # header\n",
    "    tmp = [['id', 'cuisine']]\n",
    "    \n",
    "    for i in range(len(ids)):\n",
    "        # add a row (id and class prediction)\n",
    "        tmp.append([ids[i], target[i]])\n",
    "        \n",
    "    # write CSV file\n",
    "    f = open(fname, 'wb')\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerows(tmp)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39774\n",
      "9944\n"
     ]
    }
   ],
   "source": [
    "# load the data\n",
    "traindata = load_cooking(\"train.json\")\n",
    "testdata  = load_cooking(\"test.json\")\n",
    "print len(traindata['data'])\n",
    "print len(testdata['data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'romaine lettuce', u'black olives', u'grape tomatoes', u'garlic', u'pepper', u'purple onion', u'seasoning', u'garbanzo beans', u'feta cheese crumbles']\n",
      "greek\n"
     ]
    }
   ],
   "source": [
    "# first training example\n",
    "print traindata['data'][0]\n",
    "# data is a list of ingredients\n",
    "print traindata['target'][0]\n",
    "# target is the cuisine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "[u'brazilian' u'british' u'cajun_creole' u'chinese' u'filipino' u'french'\n",
      " u'greek' u'indian' u'irish' u'italian' u'jamaican' u'japanese' u'korean'\n",
      " u'mexican' u'moroccan' u'russian' u'southern_us' u'spanish' u'thai'\n",
      " u'vietnamese']\n"
     ]
    }
   ],
   "source": [
    "# list of cuisines\n",
    "classes = unique(traindata['target'])\n",
    "print len(classes)\n",
    "print classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainY = traindata['target']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first transform the traindata['data'] and testdata['data'] to a list of recipes instead of a list  of ingredients for futher vectorization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainRecipe = []\n",
    "for li in traindata['data']:\n",
    "    s=\"\"\n",
    "    for x in li:\n",
    "        s += \" \"+x\n",
    "    trainRecipe.append(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testRecipe = []\n",
    "for li in testdata['data']:\n",
    "    s=\"\"\n",
    "    for x in li:\n",
    "        s += \" \"+x\n",
    "    testRecipe.append(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we try CountVectorizer for feature extraction. If only using the default tokenizer for the feature extraction, there are 3010 features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3010\n"
     ]
    }
   ],
   "source": [
    "tmp = feature_extraction.text.CountVectorizer()\n",
    "trainXtmp = tmp.fit_transform(trainRecipe)\n",
    "print len(tmp.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After we remove the stop_words, the features decrease to 2970."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2970\n"
     ]
    }
   ],
   "source": [
    "tmp = feature_extraction.text.CountVectorizer(stop_words='english')\n",
    "trainXtmp = tmp.fit_transform(trainRecipe)\n",
    "testXtmp = tmp.transform(testRecipe)\n",
    "print len(tmp.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the Bernoulli Naive Bayes model to train data and do prediction. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "alphasb = logspace(-4,0,10)\n",
    "avgscoresb = empty(len(alphasb))\n",
    "\n",
    "for i,al in enumerate(alphasb):       \n",
    "        bmodel = naive_bayes.BernoulliNB(alpha=al)\n",
    "        myscoreb = cross_validation.cross_val_score(bmodel, trainXtmp, trainY, cv=5)\n",
    "        avgscoresb[i] = mean(myscoreb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max acc of cross-validation = 0.718635892965\n",
      "It takes 2.203000 sec\n",
      "acc of bernoulli =  0.740760295671\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tStart = time.time()\n",
    "time.sleep(2)\n",
    "\n",
    "bestib = argmax(avgscoresb)\n",
    "bestab = alphasb[bestib]\n",
    "\n",
    "print \"max acc of cross-validation =\", avgscoresb[bestib]\n",
    "\n",
    "bmodel = naive_bayes.BernoulliNB(alpha=bestab)\n",
    "bmodel.fit(trainXtmp, trainY)\n",
    "tEnd = time.time()\n",
    "\n",
    "print \"It takes %f sec\" % (tEnd - tStart)\n",
    "\n",
    "predTrainYb = bmodel.predict(trainXtmp)\n",
    "predTestYb = bmodel.predict(testXtmp)\n",
    "\n",
    "print \"acc of bernoulli = \", mean(predTrainYb == trainY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bernoulli model runs for 2.23 seconds. The accuracy of bernoulli model on training data is 0.74076 and the testing accuray on Kaggle is 0.68142."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we try to use TF-IDF to extract features and other models to classify."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TF-IDF representation\n",
    "# (For TF, pass use_idf=False)\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tf_trans = feature_extraction.text.TfidfVectorizer(use_idf=True, stop_words='english')\n",
    "# setup the TF-IDF representation, and transform the training set\n",
    "trainX = tf_trans.fit_transform(trainRecipe) # transform the test set\n",
    "testX = tf_trans.transform(testRecipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(39774, 2970)\n"
     ]
    }
   ],
   "source": [
    "print trainX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19887, 2970)\n",
      "(19887, 2970)\n"
     ]
    }
   ],
   "source": [
    "trainXrf, testXrf, trainYrf, testYrf = \\\n",
    "            cross_validation.train_test_split(trainX, trainY,\n",
    "            train_size=0.5, test_size=0.5, random_state=4487)\n",
    "    \n",
    "print trainXrf.shape \n",
    "print testXrf.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some ingredients are more important than others, and we try the tfidf vectorizer and use Multinomial Naive Bayes Model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "alphas = logspace(-1,0,30)\n",
    "vocas = range(1000,3000,200)\n",
    "avgscores = empty((len(alphas), len(vocas)))\n",
    "\n",
    "for i,al in enumerate(alphas):\n",
    "    for j,voca in enumerate(vocas):     \n",
    "        tfvect = feature_extraction.text.TfidfVectorizer(use_idf=False, stop_words = 'english', max_features=voca)\n",
    "        trainXtf = tfvect.fit_transform(trainRecipe)\n",
    "        mmodel_tf = naive_bayes.MultinomialNB(alpha=al)      \n",
    "        myscore = cross_validation.cross_val_score(mmodel_tf, trainXtf, trainY, cv=5)\n",
    "        avgscores[i,j] = mean(myscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocabulary size =  1800\n",
      "max acc of cross-validation =  0.710112816369\n",
      "It cost 3.131339 sec\n",
      "3.13133907318\n",
      "acc of tf-idf =  0.727962990899\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "tStart = time.time()\n",
    "\n",
    "time.sleep(2)\n",
    "\n",
    "besti = argmax(avgscores)\n",
    "\n",
    "(bestia, bestiv) = unravel_index(besti, avgscores.shape)\n",
    "besta = alphas[bestia]\n",
    "bestv = vocas[bestiv]\n",
    "print \"vocabulary size = \", bestv\n",
    "print \"max acc of cross-validation = \", avgscores[bestia,bestiv]\n",
    "\n",
    "tfvect = feature_extraction.text.TfidfVectorizer(use_idf=False, max_features=bestv)\n",
    "trainXtf = tfvect.fit_transform(trainRecipe)\n",
    "    \n",
    "mmodel_tf = naive_bayes.MultinomialNB(alpha=besta)\n",
    "mmodel_tf.fit(trainXrf, trainYrf)\n",
    "\n",
    "tEnd = time.time()\n",
    "\n",
    "print \"It cost %f sec\" % (tEnd - tStart)\n",
    "print tEnd - tStart\n",
    "\n",
    "predtrainYtf = mmodel_tf.predict(testXrf)\n",
    "\n",
    "\n",
    "print \"acc of tf-idf = \", mean(predtrainYtf==testYrf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Multinomial NB model costs only about 3.1 seconds, which is much better than the random forest classifier. The training accuracy of Multinomial NB is not high (72.52%), situation in Kaggle is similiar, the accuracy is 70.746%.\n",
    "Go on and try other classifiers:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to deduct the dimensionality, nmf is selected to see if we can get higher accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nmf = decomposition.NMF(n_components=50)\n",
    "W = nmf.fit_transform(trainXrf)\n",
    "Wt = nmf.transform(testXrf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc of tf-idf =  0.279780761301\n"
     ]
    }
   ],
   "source": [
    "mmodel_tf2 = naive_bayes.MultinomialNB(alpha=besta)\n",
    "mmodel_tf2.fit(W, trainYrf)\n",
    "\n",
    "predtestYtf = mmodel_tf2.predict(Wt)\n",
    "print \"acc of tf-idf = \", mean(predtestYtf==testYrf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using NMF, compared to the MultinomiaNB Classfier without dimensionality deduction in the above (accuracy = 78.9%), this version has only an accuracy of 28%. Important features might have been deducted and we gave up on using dimensionality deductions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It cost 347.799201 sec\n",
      "347.799201012\n",
      "acc of Random Forest =  0.738522652989\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "tStart = time.time()\n",
    "\n",
    "time.sleep(2)\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "forest = RandomForestClassifier(n_estimators = 1000) \n",
    "result = forest.fit(trainXrf, trainYrf)\n",
    "\n",
    "tEnd = time.time()\n",
    "print \"It cost %f sec\" % (tEnd - tStart)\n",
    "print tEnd - tStart\n",
    "\n",
    "predTrainRF = forest.predict(testXrf)\n",
    "print \"acc of Random Forest = \", mean(predTrainRF == testYrf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Random Forest Classifier costs 348 seconds, which is time-consuming. When we used it to train the whole training dataset, it needed 100 more seconds. Its accuracy is about 76.78% in Kaggle. Though the result is not bad, the efficiency of Random Forest Classifier is barely satisfactory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It cost 3.388000 sec\n",
      "3.38800001144\n",
      "acc of tf-idf =  0.777140845779\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "tStart = time.time()\n",
    "\n",
    "time.sleep(2)\n",
    "\n",
    "clf = svm.LinearSVC(C=0.8)\n",
    "clf.fit(trainXrf, trainYrf)\n",
    "\n",
    "tEnd = time.time()\n",
    "\n",
    "print \"It cost %f sec\" % (tEnd - tStart)\n",
    "print tEnd - tStart\n",
    "\n",
    "predtrainYtf = clf.predict(testXrf)\n",
    "\n",
    "print \"acc of tf-idf = \", mean(predtrainYtf==testYrf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The speed of Lineaer SVC is also good (about 3.4 seconds) and it is even slight faster than the Multinomial NB. After using LinearSVC to train the trainXtf data, the accuracy is 78.268% in Kaggle. The accuracy is relately higher than other classifiers needing only 3.089 seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It cost 13.354000 sec\n",
      "13.3539998531\n",
      "acc of decision tree =  0.594458691608\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "tStart = time.time()\n",
    "\n",
    "time.sleep(2)\n",
    "\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "clf.fit(trainXrf, trainYrf)\n",
    "\n",
    "tEnd = time.time()\n",
    "\n",
    "print \"It cost %f sec\" % (tEnd - tStart)\n",
    "print tEnd - tStart\n",
    "\n",
    "predtestYt=clf.predict(testXrf)\n",
    "print \"acc of decision tree = \", mean(predtestYt == testYrf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Decision Tree Classifier, we got an accuracy of 59% in Kaggle, similar to the training accuracy here, which is much lower than other classifiers and implemented slower (about 13.35 seconds)than Multinomial NB classifier or Linear SVC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It cost 12.666446 sec\n",
      "12.6664459705\n",
      "accuracy= 0.764620103585\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "tStart = time.time()\n",
    "\n",
    "time.sleep(2)\n",
    "\n",
    "logreg = linear_model.LogisticRegression(C=100) \n",
    "logreg.fit(trainXrf, trainYrf)\n",
    "\n",
    "tEnd = time.time()\n",
    "\n",
    "print \"It cost %f sec\" % (tEnd - tStart)\n",
    "print tEnd - tStart\n",
    "\n",
    "# predict from the model\n",
    "predY = logreg.predict(testXrf)\n",
    "# calculate accuracy\n",
    "Ncorrect = sum(testYrf==predY) \n",
    "acc = mean(testYrf==predY) \n",
    "print \"accuracy=\", acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To sum up, we choose to focus on logistic regression and go on with further exploration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Noticed that there are some french characters, numbers and punctuations, we re-write the generation of list of recipe to remove or replace them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "trainRecipe = []\n",
    "for li in traindata['data']:\n",
    "    s=\"\"\n",
    "    for x in li:\n",
    "        x=re.sub('-','_',x)\n",
    "        s += ' '+re.sub(r'[^a-zA-Z_ ]','',x) # keep the underscore\n",
    "    trainRecipe.append(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testRecipe = []\n",
    "for li in testdata['data']:\n",
    "    s=\"\"\n",
    "    for x in li:\n",
    "        x=re.sub('-','_',x)\n",
    "        s += ' '+re.sub(r'[^a-zA-Z_ ]','',x) # keep the underscore\n",
    "    testRecipe.append(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use TfidfVectorizer to vectorize the clean trainRecipe data and logistic regression to train it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfvect = TfidfVectorizer(stop_words='english')\n",
    "trainXtf = tfvect.fit_transform(trainRecipe)\n",
    "testXtf = tfvect.transform(testRecipe)\n",
    "logreg = linear_model.LogisticRegressionCV(Cs=logspace(1,10,10), cv=5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc of logistic regression =  0.858475385931\n"
     ]
    }
   ],
   "source": [
    "logreg.fit(trainXtf, trainY)\n",
    "\n",
    "predTrainYlr = logreg.predict(trainXtf)\n",
    "predTestYlr = logreg.predict(testXtf)\n",
    "\n",
    "print \"acc of logistic regression = \", mean(predTrainYlr == trainY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training accuracy . The final accuracy in the Kaggle is 78.872%. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'23', u'24', u'25', u'26', u'27', u'28', u'29', u'30', u'31', u'32', u'33', u'34', u'35', u'36', u'38', u'40', u'43', u'49', u'52', u'59', u'65', u'aai', u'abalone', u'abbamele', u'absinthe', u'abura', u'acai', u'accent', u'accompaniment', u'achiote', u'acid', u'acini', u'ackee', u'acorn', u'active', u'added', u'adobo', u'adzuki', u'agar', u'agave', u'age', u'aged', u'ahi', u'aioli', u'ajinomoto', u'ajwain', u'aka', u'alaskan', u'albacore', u'alcohol', u'ale', u'aleppo', u'alexia', u'alfalfa', u'alfredo', u'all_purpose', u'allspice', u'almond', u'almondmilk', u'almonds', u'aloe', u'alphabet', u'alum', u'amaranth', u'amarena', u'amaretti', u'amaretto', u'amba', u'amber', u'amberjack', u'amchur', u'america', u'american', u'aminos', u'ammonium', u'amontillado', u'ampalaya', u'anaheim', u'anasazi', u'ancho', u'anchovies', u'anchovy', u'andouille', u'anejo', u'angel', u'anglaise', u'angled', u'angostura', u'angus', u'anise', u'anisette', u'anjou', u'annatto', u'aonori', u'apple', u'apples', u'applesauce', u'applewood', u'apricot', u'apricots', u'aquavit', u'arak', u'arame', u'arbol', u'arborio', u'arctic', u'arepa', u'argo', u'arhar', u'armagnac', u'arrabbiata', u'arrow', u'arrowroot', u'artichok', u'artichoke', u'artichokes', u'artificial', u'artisan', u'arugula', u'asada', u'asadero', u'asafetida', u'asafoetida', u'asakusa', u'ascorbic', u'asiago', u'asian', u'asparagus', u'aspic', u'assam', u'assorted', u'asti', u'atlantic', u'atta', u'au', u'avocado', u'avocados', u'awase', u'azteca', u'azuki', u'baby', u'bacardi', u'bacon', u'bag', u'bagel', u'bagels', u'bags', u'baguette', u'bai', u'baileys', u'baked', u'baking', u'balance', u'balls', u'balm', u'balsamic', u'balsamico', u'bamboo', u'banana', u'bananas', u'banger', u'banh', u'baobab', u'bar', u'barbecue', u'barbecued', u'barberries', u'barilla', u'bark', u'barley', u'barolo', u'barramundi', u'bars', u'bartlett', u'basa', u'base', u'basil', u'basmati', u'bass', u'baton', u'batter', u'bawang', u'bay', u'bayonne', u'bbq', u'bean', u'beans', u'beansprouts', u'bear', u'beaten', u'beaters', u'beau', u'beaujolais', u'bechamel', u'bee', u'beech', u'beef', u'beefsteak', u'beer', u'beet', u'beetroot', u'beets', u'belacan', u'belgian', u'believ', u'believe', u'bell', u'bellpepper', u'bells', u'belly', u'beluga', u'bengal', u'bengali', u'beni', u'benne', u'bens', u'bermuda', u'berries', u'bertolli', u'besan', u'best', u'better', u'betty', u'beurre', u'beverage', u'beverages', u'bhaji', u'bhindi', u'bianco', u'bibb', u'bicarbonate', u'big', u'biga', u'bigoli', u'bihon', u'bing', u'bird', u'biryani', u'biscotti', u'biscuit', u'biscuits', u'bison', u'bisquick', u'bits', u'bitter', u'bitters', u'bittersweet', u'blacan', u'black', u'black_eyed', u'blackberries', u'blackberry', u'blackcurrant', u'blackened', u'blackening', u'blackpepper', u'blackstrap', u'blade', u'blanc', u'blanched', u'blanco', u'blend', u'blends', u'bliss', u'block', u'blood', u'bloody', u'blossom', u'blossoms', u'blue', u'blueberri', u'blueberries', u'blueberry', u'bndictine', u'boar', u'bob', u'bocconcini', u'bock', u'boil', u'boiled', u'boiling', u'bok', u'bolillo', u'bologna', u'bone', u'bone_in', u'boned', u'boneless', u'bones', u'bonito', u'bonnet', u'boquerones', u'borage', u'bordelaise', u'borlotti', u'bosc', u'boston', u'bottle', u'bottled', u'bottoms', u'boudin', u'bought', u'bouillon', u'bouquet', u'bourbon', u'boursin', u'bow_tie', u'bows', u'boy', u'boysenberries', u'braeburn', u'bragg', u'braggs', u'braising', u'bran', u'branca', u'brand', u'brandy', u'branston', u'branzino', u'brats', u'bratwurst', u'brazil', u'bread', u'breadcrumb', u'breadcrumbs', u'breader', u'breadfruit', u'breadstick', u'breakfast', u'breakstones', u'bream', u'breast', u'breasts', u'bresaola', u'brew', u'brewed', u'breyers', u'brie', u'brill', u'brine', u'brine_cured', u'brioche', u'brise', u'brisket', u'brittle', u'broad', u'broccoli', u'broccolini', u'broil', u'broiler', u'broiler_fryer', u'broiler_fryers', u'broth', u'brown', u'brownie', u'brownies', u'browning', u'browns', u'brussels', u'btarde', u'bucatini', u'buckwheat', u'buds', u'budweiser', u'buffalo', u'bulb', u'bulgur', u'bulk', u'bun', u'buns', u'burdock', u'burger', u'burgers', u'burgundi', u'burgundy', u'burrata', u'burrito', u'burro', u'bushi', u'butt', u'butter', u'butter_flavored', u'butter_margarine', u'buttercream', u'buttercup', u'butterflied', u'buttermilk', u'butternut', u'butterscotch', u'buttery', u'button', u'cabbage', u'cabernet', u'cabrales', u'cacao', u'cachaca', u'caciocavallo', u'cactus', u'caesar', u'cai', u'cajeta', u'cajun', u'cajun_creole', u'cake', u'cakes', u'calabash', u'calabaza', u'calabrese', u'calamansi', u'calamari', u'calamata', u'calcium', u'calf', u'california', u'calimyrna', u'callaloo', u'calorie', u'calvados', u'camellia', u'camembert', u'campanelle', u'campari', u'campbells', u'canadian', u'candied', u'candlenuts', u'candy', u'cane', u'canela', u'canes', u'canned', u'cannellini', u'cannelloni', u'canning', u'cannoli', u'canola', u'cantal', u'cantaloupe', u'canton', u'capellini', u'caper', u'capers', u'capicola', u'capocollo', u'capon', u'caponata', u'cappuccino', u'caps', u'capsicum', u'cara', u'carambola', u'caramel', u'caramels', u'caraway', u'carbonated', u'carcass', u'cardamom', u'cardamon', u'cardoons', u'caribbean', u'carnaroli', u'carnation', u'carne', u'carnitas', u'carp', u'carpaccio', u'carrot', u'carrots', u'casa', u'cascabel', u'casera', u'cashew', u'cashews', u'casing', u'casings', u'cassava', u'cassia', u'cassis', u'castellane', u'castelvetrano', u'caster', u'catalina', u'catfish', u'catsup', u'caul', u'cauliflower', u'cauliflowerets', u'cava', u'cavatappi', u'cavatelli', u'cavenders', u'caviar', u'cavolo', u'cayenne', u'ceci', u'celery', u'celtic', u'center', u'center_cut', u'century', u'cereal', u'ceylon', u'chaat', u'chacheres', u'chai', u'challa', u'challenge', u'cham', u'chambord', u'champagne', u'chana', u'chang', u'channa', u'chanterelle', u'chapati', u'chapatti', u'char', u'chard', u'chardonnay', u'chartreuse', u'chat', u'chateaubriand', u'chayotes', u'cheddar', u'chee', u'cheek', u'cheeks', u'chees', u'cheese', u'cheesi', u'chenpi', u'cheong', u'cherries', u'cherry', u'cherrystone', u'chervil', u'chestnut', u'chestnuts', u'chevre', u'chia', u'chianti', u'chicharron', u'chicken', u'chicken_apple', u'chicken_flavored', u'chickens', u'chickpea', u'chickpeas', u'chicory', u'chiffonade', u'chihuahua', u'chikn', u'chilcostle', u'chile', u'chilean', u'chilegarlic', u'chiles', u'chili', u'chilies', u'chilled', u'chilli', u'chillies', u'chiltepn', u'chimichurri', u'chinese', u'chinkiang', u'chioggia', u'chip', u'chipotl', u'chipotle', u'chipotles', u'chipped', u'chips', u'chitterlings', u'chive', u'chives', u'cho_cho', u'chocolate', u'chocolate_hazelnut', u'chocolatecovered', u'choi', u'cholesterol', u'cholula', u'chong', u'chop', u'chopmeat', u'chopped', u'chops', u'chorizo', u'chourico', u'chow', u'chowchow', u'choy', u'chrysanthemum', u'chua', u'chuck', u'chuka', u'chunk', u'chunks', u'chunky', u'chuno', u'chutney', u'chvre', u'ciabatta', u'cider', u'cilantro', u'cinnamon', u'cipollini', u'citric', u'citron', u'citrus', u'clam', u'clamato', u'clams', u'clarified', u'classic', u'classico', u'claws', u'clear', u'clementine', u'clementines', u'clotted', u'cloud', u'clove', u'clover', u'cloves', u'club', u'coars', u'coarse', u'coarse_grain', u'coca_cola', u'cockles', u'cocktail', u'coco', u'cocoa', u'coconut', u'cod', u'codfish', u'coffee', u'cognac', u'cointreau', u'coke', u'cola', u'cola_flavored', u'colada', u'colby', u'cold', u'cold_smoked', u'cole', u'coleslaw', u'collard', u'collards', u'collect', u'colmans', u'color', u'colorado', u'coloring', u'colouring', u'comfort', u'comice', u'comino', u'compote', u'compressed', u'concentrate', u'conch', u'conchiglie', u'condensed', u'condiments', u'cones', u'confectioners', u'confit', u'conger', u'conimex', u'consomme', u'convert', u'converted', u'cook', u'cooked', u'cooki', u'cookie', u'cookies', u'cooking', u'cool', u'cordial', u'coriander', u'corkscrew', u'corn', u'corn_on_the_cob', u'cornbread', u'corned', u'cornflake', u'cornflakes', u'cornflour', u'cornhusks', u'cornichons', u'cornish', u'cornmeal', u'cornstarch', u'cortland', u'cotija', u'cottage', u'cotto', u'coulis', u'country', u'country_style', u'couscous', u'covered', u'coxs', u'crab', u'crabapples', u'crabmeat', u'crabs', u'cracked', u'cracker', u'crackers', u'cranberries', u'cranberry', u'crawfish', u'crawford', u'crayfish', u'cream', u'creamed', u'creamer', u'creami', u'creamy', u'creations', u'crema', u'creme', u'cremini', u'creole', u'crepes', u'crescent', u'cress', u'crimini', u'crisco', u'crisp_cooked', u'crisps', u'crispy', u'crme', u'crock', u'crocker', u'croissant', u'croissants', u'crookneck', u'cross', u'crosswise', u'crostini', u'crouton', u'croutons', u'crumb', u'crumbled', u'crumbles', u'crumbs', u'crumpet', u'crunch', u'crush', u'crushed', u'crust', u'crusts', u'crusty', u'crystal', u'crystallized', u'cuban', u'cube', u'cubed', u'cubes', u'cucumber', u'cucumbers', u'cucuzza', u'cuervo', u'cuisine', u'culantro', u'culinary', u'cultured', u'cumberland', u'cumin', u'cuminseed', u'cummin', u'cups', u'curaao', u'curd', u'curds', u'cured', u'curing', u'curls', u'curly', u'curly_leaf', u'currant', u'currants', u'curry', u'custard', u'cut', u'cutlet', u'cutlets', u'cuts', u'cuttlefish', u'daal', u'daikon', u'dairy', u'daisy', u'daiya', u'dal', u'dandelion', u'dangmyun', u'daniels', u'darjeeling', u'dark', u'dash', u'dasheen', u'dashi', u'date', u'dates', u'day', u'dean', u'decorating', u'deep', u'deep_fried', u'delallo', u'deli', u'delicata', u'delicious', u'demerara', u'demi', u'demi_glace', u'dende', u'despelette', u'dessert', u'devein', u'deveined', u'deviled', u'devils', u'dew', u'dhal', u'dhaniya', u'di', u'diamond', u'diced', u'dickel', u'diet', u'digestive', u'dijon', u'dijonnaise', u'dill', u'dillweed', u'dinner', u'dinosaur', u'dip', u'dipping', u'dips', u'disco', u'dish', u'distilled', u'ditalini', u'doenzang', u'dog', u'dogs', u'dolce', u'dole', u'domino', u'doritos', u'doubanjiang', u'doubl', u'double', u'double_acting', u'double_dark', u'dough', u'doughs', u'dr', u'dragees', u'dragon', u'drain', u'drained', u'drambuie', u'dress', u'dressing', u'dri', u'dried', u'drink', u'drippings', u'drum', u'drummettes', u'drumstick', u'drumsticks', u'dry', u'du', u'duck', u'ducklings', u'dukkah', u'dulce', u'dulong', u'dumpling', u'dumplings', u'dungeness', u'durum', u'dusting', u'dutch_processed', u'duxelles', u'e_fu', u'ear', u'earl', u'ears', u'earth', u'eating', u'eau', u'eau_de_vie', u'edam', u'edamame', u'edible', u'eel', u'egg', u'egglands', u'eggnog', u'eggplant', u'eggplants', u'eggroll', u'eggs', u'el', u'elbow', u'elderflower', u'elmlea', u'emerils', u'emmenthal', u'empanada', u'enchilada', u'endive', u'energy', u'english', u'enokitake', u'enriched', u'epazote', u'equal', u'erythritol', u'escalopes', u'escargot', u'escarole', u'espresso', u'essence', u'estancia', u'european', u'evans', u'evapor', u'evaporated', u'everglades', u'extra', u'extra_lean', u'extra_virgin', u'extract', u'eye', u'fajita', u'falafel', u'family', u'farfalline', u'farina', u'farm', u'farmer', u'farmhouse', u'farms', u'farofa', u'farro', u'fashioned', u'fast', u'fast_rising', u'fat', u'fat_free', u'fat_trimmed', u'fatback', u'fatfre', u'fatfree', u'fats', u'fava', u'fedelini', u'feet', u'fennel', u'fenugreek', u'fermented', u'fern', u'ferns', u'feta', u'fettuccine', u'fettuccini', u'fettucine', u'fiber', u'ficelle', u'fiddlehead', u'fideos', u'field', u'fiesta', u'fig', u'figs', u'fil', u'file', u'filet', u'filets', u'filipino', u'filled', u'fillet', u'fillets', u'filling', u'filo', u'fine', u'finely', u'fines', u'finger', u'fingerling', u'fingers', u'fino', u'firm', u'firmly', u'fish', u'fishcake', u'fisher', u'five_spice', u'flageolet', u'flake', u'flaked', u'flakes', u'flan', u'flank', u'flanken', u'flat', u'flatbread', u'flavor', u'flavored', u'flavoring', u'flax', u'flaxseed', u'fleshed', u'fleur', u'flora', u'florets', u'flounder', u'flour', u'flower', u'flowerets', u'flowering', u'flowers', u'fluff', u'focaccia', u'foccacia', u'foie', u'fondant', u'fontina', u'food', u'foods', u'forest', u'foster', u'fowl', u'frache', u'framboise', u'frangelico', u'frangipane', u'frankfurters', u'franks', u'free', u'free_range', u'freeze_dried', u'fregola', u'french', u'fresca', u'fresco', u'fresh', u'freshly', u'fresno', u'fri', u'fried', u'fries', u'frisee', u'friselle', u'fritos', u'frogs', u'fromage', u'fronds', u'frosting', u'frostings', u'frozen', u'fructose', u'fruit', u'fruitcake', u'fruits', u'fry', u'fryer', u'fryers', u'frying', u'fudge', u'fuji', u'full_fat', u'fully', u'fume', u'fungus', u'furikake', u'fusilli', u'fuyu', u'gaeta', u'gai', u'gala', u'galanga', u'galangal', u'galliano', u'gallo', u'game', u'ganache', u'gao', u'garam', u'garbanzo', u'garbanzos', u'garbonzo', u'garden', u'gari', u'garland', u'garlic', u'garni', u'garnish', u'gebhardt', u'gel', u'gelatin', u'gelato', u'gem', u'gember', u'gemelli', u'genmai', u'genoa', u'genoise', u'george', u'germ', u'germain', u'german', u'ghee', u'gherkin', u'gherkins', u'giant', u'giardiniera', u'giblet', u'gin', u'ginger', u'gingerroot', u'gingersnap', u'ginkgo', u'ginseng', u'gizzards', u'glace', u'glacs', u'glass', u'glaze', u'glazed', u'globe', u'glucose', u'gluten', u'gluten_free', u'glutinous', u'gnocchetti', u'gnocchi', u'goat', u'goats', u'gobo', u'gochugaru', u'gochujang', u'godiva', u'goji', u'gold', u'golden', u'goma', u'gomashio', u'good', u'goose', u'gooseberries', u'goreng', u'gorgonzola', u'gouda', u'gourd', u'gourmet', u'goya', u'grade', u'graham', u'grain', u'grained', u'gram', u'gran', u'grana', u'granary', u'grand', u'granita', u'granny', u'granola', u'granular', u'granulated', u'granules', u'grape', u'grapefruit', u'grapes', u'grapeseed', u'grappa', u'gras', u'grass', u'grass_fed', u'grassfed', u'grate', u'grated', u'grating', u'gravenstein', u'graviera', u'gravlax', u'gravy', u'gray', u'grease', u'great', u'greater', u'greek', u'greek_style', u'greekstyl', u'green', u'greens', u'gremolata', u'grenadine', u'grey', u'grigio', u'grill', u'grilled', u'grilling', u'grind', u'grissini', u'grit', u'grits', u'groats', u'ground', u'groundnut', u'grouper', u'gruyere', u'gruyre', u'guacamol', u'guacamole', u'guajillo', u'guanabana', u'guanciale', u'guava', u'guinea', u'guinness', u'gum', u'gumbo', u'guy', u'gyoza', u'haas', u'habanero', u'habas', u'hachiya', u'haddock', u'hair', u'hake', u'hakusai', u'half', u'half_and_half', u'halibut', u'halloumi', u'haloumi', u'halves', u'ham', u'hamachi', u'hamburger', u'hand', u'hanger', u'hanh', u'hanout', u'hard', u'hard_boiled', u'haricot', u'haricots', u'harina', u'harissa', u'harusame', u'harvest', u'hash', u'hass', u'hatch', u'hatcho', u'havarti', u'hawaiian', u'hazelnut', u'hazelnuts', u'head', u'heads', u'heart', u'hearts', u'heath', u'heavy', u'heeng', u'heinz', u'heirloom', u'helix', u'hellmann', u'hellmanns', u'hemp', u'hen', u'hens', u'herb', u'herbed', u'herbes', u'herbs', u'herbsaint', u'herdez', u'hero', u'herring', u'hibiscus', u'hickory', u'hickory_flavored', u'hidden', u'hierba', u'high', u'high_fructose', u'high_gluten', u'hijiki', u'hillshire', u'himalayan', u'hing', u'hip', u'hoagi', u'hoagie', u'hock', u'hocks', u'hog', u'hogue', u'hoi', u'hoisin', u'hoja', u'holland', u'hollandaise', u'holy', u'home', u'homemade', u'homestyl', u'hominy', u'honey', u'honey_flavored', u'honeycomb', u'honeydew', u'honeysuckle', u'hong', u'hoop', u'hops', u'horseradish', u'hot', u'hothouse', u'hots', u'house', u'hsing', u'hubbard', u'huckleberries', u'huitlacoche', u'hummus', u'hungarian', u'hurst', u'husks', u'hyssop', u'ibarra', u'ic', u'ice', u'iceberg', u'iced', u'icing', u'idaho', u'idli', u'ikura', u'imitation', u'imo', u'imperial', u'inch', u'india', u'indian', u'instant', u'iodized', u'irish', u'iron', u'island', u'islands', u'italian', u'italian_style', u'jack', u'jackfruit', u'jagermeister', u'jaggery', u'jalape', u'jalapeno', u'jalapenos', u'jam', u'jamaica', u'jamaican', u'jambalaya', u'jambon', u'jameson', u'jamon', u'japanese', u'jarlsberg', u'jarred', u'jasmine', u'jeera', u'jell_o', u'jelli', u'jello', u'jelly', u'jerk', u'jerky', u'jerusalem', u'jicama', u'jif', u'jiffy', u'jimmies', u'jimmy', u'johnsonville', u'jonshonville', u'jose', u'jowl', u'juice', u'jujube', u'jujubes', u'jumbo', u'juniper', u'jus', u'kabocha', u'kabuli', u'kaffir', u'kahla', u'kahlua', u'kaiser', u'kalamansi', u'kalamata', u'kale', u'kalonji', u'kamaboko', u'kampyo', u'kamut', u'kangkong', u'kappa', u'karashi', u'karo', u'kasha', u'kashmiri', u'kasseri', u'kasu', u'kasuri', u'katakuriko', u'katsuo', u'kecap', u'keema', u'kefalotiri', u'kefalotyri', u'kefir', u'kelp', u'kernel', u'kernels', u'kerrygold', u'ketchup', u'ketjap', u'kewpie', u'kewra', u'key', u'kha', u'khoa', u'kidnei', u'kidney', u'kidneys', u'kielbasa', u'kikkoman', u'kim', u'kimchi', u'kinchay', u'king', u'kingfish', u'kippered', u'kippers', u'kirby', u'kirsch', u'kirschenliqueur', u'kirschwasser', u'kisses', u'kitchen', u'kiwi', u'kiwifruit', u'klondike', u'knoblauch', u'knockwurst', u'knoflook', u'knorr', u'knox', u'knuckle', u'knudsen', u'kochu', u'kochujang', u'kohlrabi', u'kokum', u'komatsuna', u'kombu', u'konbu', u'kong_style', u'konnyaku', u'korean', u'korma', u'kosher', u'kraft', u'krispies', u'kroger', u'kumquats', u'kung', u'la', u'lacinato', u'lady', u'ladyfingers', u'ladys', u'lager', u'lakes', u'laksa', u'lamb', u'lambic', u'lambrusco', u'lambs', u'lan', u'land', u'langoustines', u'lap', u'lapsang', u'lard', u'lardons', u'large', u'lasagna', u'lasagne', u'laurel', u'lavash', u'lavender', u'layer', u'lb', u'lea', u'leaf', u'leafy', u'lean', u'leav', u'leaves', u'leche', u'lecithin', u'leek', u'leeks', u'leftover', u'leg', u'legs', u'legumes', u'lemon', u'lemon_lime', u'lemonade', u'lemongrass', u'lentil', u'lentilles', u'lentils', u'lesser', u'lettuc', u'lettuce', u'lettuces', u'levain', u'licor', u'licorice', u'light', u'lillet', u'lily', u'lima', u'lime', u'limeade', u'limoncello', u'lingcod', u'linguica', u'linguine', u'linguini', u'linguisa', u'links', u'lipton', u'liqueur', u'liquid', u'liquor', u'liquorice', u'lite', u'littleneck', u'liver', u'livers', u'liverwurst', u'lo', u'loaf', u'loaves', u'lobster', u'lobsters', u'loin', u'london', u'long', u'long_grain', u'longan', u'longaniza', u'loofah', u'loose', u'loosely', u'lop', u'lotus', u'louisiana', u'low', u'low_fat', u'low_moisture', u'low_sodium', u'lower', u'lowfat', u'lowsodium', u'lox', u'luke', u'lump', u'lumpia', u'luncheon', u'lychees', u'maca', u'macadamia', u'macaroni', u'macarons', u'mace', u'machine', u'mackerel', u'madagascar', u'madeira', u'madeleine', u'madras', u'mae', u'maggi', u'magret', u'mahi', u'mahimahi', u'mahlab', u'maida', u'maifun', u'maitake', u'makers', u'maldon', u'malt', u'malted', u'maltose', u'mam', u'manchego', u'mandarin', u'mango', u'mani', u'manicotti', u'manioc', u'manis', u'manischewitz', u'manouri', u'mantou', u'manzanilla', u'maple', u'maraschino', u'marble', u'marcona', u'margarine', u'margarita', u'margherita', u'marin', u'marinade', u'marinara', u'marjoram', u'mark', u'marmalade', u'marmite', u'marnier', u'marrons', u'marrow', u'marsala', u'marshmallow', u'marshmallows', u'martha', u'mary', u'marzano', u'marzipan', u'masa', u'masago', u'masala', u'mascarpone', u'mashed', u'masoor', u'massaman', u'master', u'masur', u'matcha', u'matsutake', u'mature', u'matzo', u'matzos', u'maui', u'mayer', u'mayonaise', u'mayonnais', u'mayonnaise', u'mazola', u'mccormick', u'mcintosh', u'meal', u'meat', u'meat_filled', u'meatballs', u'meatloaf', u'meats', u'medal', u'medallions', u'medium', u'medium_grain', u'medjool', u'mein', u'melba', u'melissa', u'mellow', u'melon', u'melted', u'membrillo', u'menta', u'mentaiko', u'menthe', u'mentsuyu', u'merguez', u'meringue', u'merlot', u'merluza', u'mesclun', u'mesquite', u'methi', u'mex', u'mexican', u'mexicana', u'mexico', u'mexicorn', u'meyer', u'mezcal', u'mezzetta', u'mi', u'mian', u'microgreens', u'mie', u'mignon', u'mild', u'milk', u'milkfat', u'milkfish', u'millet', u'min', u'mince', u'minced', u'mincemeat', u'mineral', u'mini', u'miniature', u'minicub', u'minicubes', u'mint', u'minute', u'miracle', u'mirin', u'mirlitons', u'miso', u'mission', u'miswa', u'mitsuba', u'mix', u'mixed', u'mixers', u'mixture', u'mizkan', u'mizuna', u'mms', u'mo', u'mochi', u'mochiko', u'moisture', u'mojo', u'molasses', u'mole', u'mondavi', u'monde', u'monkfish', u'monterey', u'montreal', u'mooli', u'moong', u'moonshine', u'moose', u'mora', u'morcilla', u'morel', u'moroccan', u'morsels', u'mortadella', u'morton', u'moss', u'mostaccioli', u'mostarda', u'moulard', u'mountain', u'mousse', u'mozarella', u'mozzarella', u'mrs', u'msg', u'muenster', u'muesli', u'muffin', u'muffins', u'mulato', u'mullet', u'multi_grain', u'multigrain', u'mung', u'muscadet', u'muscadine', u'muscat', u'muscavado', u'muscovado', u'muscovy', u'mushroom', u'mushrooms', u'mussels', u'mustard', u'mutton', u'myzithra', u'naan', u'nacho', u'nakano', u'nam', u'nama', u'napa', u'nappa', u'nashi', u'natto', u'natural', u'navel', u'navy', u'neapolitan', u'neck', u'nectar', u'nectarines', u'needles', u'neem', u'negi', u'negro', u'nero', u'nestle', u'nests', u'nettle', u'neufchtel', u'neutral', u'new', u'ngo', u'nian', u'niblets', u'nibs', u'nido', u'nielsen_massey', u'nigari', u'nigella', u'nilla', u'nioise', u'no_calorie', u'no_salt_added', u'no_stick', u'noir', u'non', u'non_dairy', u'non_fat', u'nondairy', u'nonfat', u'nonhydrogenated', u'nonpareils', u'nonstick', u'noodl', u'noodle', u'noodles', u'nopales', u'nopalitos', u'nori', u'northern', u'nugget', u'nuggets', u'nuoc', u'nut', u'nutella', u'nutmeg', u'nutmegs', u'nutritional', u'nuts', u'oat', u'oatmeal', u'oats', u'obrien', u'ocean', u'octopuses', u'ogura_an', u'oigatsuo', u'oil', u'oil_cured', u'okra', u'old', u'old_fashioned', u'olek', u'oleo', u'olie', u'oliv', u'olive', u'olives', u'oloroso', u'onion', u'onions', u'opo', u'orang', u'orange', u'oranges', u'orchid', u'orecchiette', u'oregano', u'oreo', u'organic', u'orgeat', u'oriental', u'original', u'originals', u'ornamental', u'ortega', u'orzo', u'oscar', u'osetra', u'ounc', u'ouzo', u'oven_ready', u'ox', u'oxtails', u'oyster', u'oyster_flavor', u'oysters', u'oz', u'paccheri', u'pace', u'pack', u'packed', u'pad', u'padano', u'paddles', u'paddy', u'padron', u'paella', u'pain', u'pak', u'pale', u'palm', u'pam', u'pan', u'panang', u'pancake', u'pancakes', u'pancetta', u'panch', u'pancit', u'pandan', u'pandanus', u'pane', u'paneer', u'panela', u'panetini', u'panettone', u'pangasius', u'panko', u'pansies', u'pao', u'papad', u'papalo', u'papaya', u'paper', u'pappadams', u'pappardelle', u'paprika', u'paratha', u'parboiled', u'pareve', u'parma', u'parmagiano', u'parmesan', u'parmigiana_reggiano', u'parmigiano', u'parmigiano_reggiano', u'parslei', u'parsley', u'parsnips', u'part_skim', u'parts', u'pasilla', u'paso', u'passata', u'passion', u'passover', u'pasta', u'paste', u'pastina', u'pastis', u'pastry', u'pat', u'pate', u'patis', u'patties', u'pattypan', u'pea', u'peach', u'peaches', u'peanut', u'peanuts', u'peapods', u'pear', u'pearl', u'pearled', u'pearls', u'pears', u'peas', u'peasant', u'pecan', u'pecans', u'pecorino', u'pectin', u'peel', u'peeled', u'pekin', u'pekoe', u'penn', u'penne', u'pepe', u'peperoncini', u'peperoncino', u'pepitas', u'peppadews', u'pepper', u'peppercorn', u'peppercorns', u'peppered', u'pepperidge', u'peppermint', u'pepperocini', u'pepperoncini', u'pepperoni', u'peppers', u'perch', u'perciatelli', u'perilla', u'pernod', u'perrins', u'persian', u'persimmon', u'persimmons', u'pesto', u'petals', u'pete', u'petit', u'petite', u'petits', u'petrale', u'pheasant', u'philadelphia', u'pho', u'phoran', u'phyllo', u'picante', u'piccolini', u'pices', u'picholine', u'pickapeppa', u'pickle', u'pickled', u'pickles', u'pickling', u'picnic', u'pico', u'pie', u'piece', u'pieces', u'piecrust', u'piecrusts', u'pierogi', u'pies', u'pig', u'pigeon', u'pignolis', u'pigs', u'pike', u'pilaf', u'pillsbury', u'piloncillo', u'pilsner', u'piment', u'pimento', u'pimenton', u'pimentos', u'pina', u'pine', u'pineapple', u'pineapples', u'pinenuts', u'pinhead', u'pink', u'pinot', u'pinto', u'pippin', u'piquillo', u'piquin', u'piri_piri', u'pisco', u'pistachio', u'pistachios', u'pistou', u'pit', u'pita', u'pitas', u'pitted', u'pizza', u'pla', u'plain', u'plantains', u'ploy', u'plum', u'plums', u'plus', u'poblano', u'pocket', u'pockets', u'pod', u'pods', u'poha', u'poi', u'pointed', u'points', u'poire', u'pois', u'polenta', u'polish', u'pollen', u'pollock', u'pomegranate', u'pomelo', u'pompano', u'pompeian', u'ponzu', u'poolish', u'pop', u'popcorn', u'poppadoms', u'popped', u'poppy', u'poppyseeds', u'porcini', u'pork', u'porridge', u'port', u'portabello', u'porter', u'porterhouse', u'portobello', u'portuguese', u'posole', u'pot', u'potato', u'potatoes', u'pots', u'potsticker', u'poultry', u'pound', u'poundcake', u'poured', u'poussins', u'powder', u'powdered', u'pozole', u'praline', u'prawn', u'prawns', u'prebaked', u'precooked', u'prego', u'premium', u'prepar', u'prepared', u'preserv', u'preserved', u'preserves', u'preshred', u'pressed', u'pretzels', u'prik', u'primavera', u'prime', u'proactiv', u'process', u'processed', u'progresso', u'promise', u'prosciutto', u'proscuitto', u'prosecco', u'protein', u'provence', u'provolone', u'prune', u'prunes', u'psyllium', u'pt', u'pte', u'pudding', u'puff', u'puffed', u'puffs', u'pullman', u'pulp', u'pummelo', u'pumpernickel', u'pumpkin', u'pumpkinseed', u'pumpkinseeds', u'pure', u'puree', u'purple', u'purpos', u'purpose', u'puy', u'qua', u'quahog', u'quail', u'quarters', u'quatre', u'queso', u'quick', u'quick_cooking', u'quickcooking', u'quince', u'quinces', u'quinoa', u'quorn', u'rabbit', u'rabe', u'rack', u'racks', u'raclette', u'radicchio', u'radish', u'radishes', u'ragu', u'rainbow', u'raisin', u'raising', u'raisins', u'raita', u'rajma', u'raki', u'ramen', u'ramps', u'ranch', u'ranch_style', u'range', u'rape', u'rapeseed', u'rapid', u'ras', u'rashers', u'raspberri', u'raspberries', u'raspberry', u'ratatouille', u'ravioli', u'ravva', u'raw', u'razor', u'ready', u'ready_made', u'real', u'reblochon', u'recip', u'recipe', u'red', u'redcurrant', u'redfish', u'redhot', u'reduc', u'reduced', u'reduced_fat', u'reduced_sodium', u'reduction', u'refined', u'refried', u'refrigerated', u'reggiano', u'regular', u'relish', u'remoulade', u'rendered', u'rennet', u'reposado', u'rhubarb', u'rib', u'rib_eye', u'ribeye', u'riblets', u'ribs', u'ricard', u'rice', u'rich', u'ricotta', u'riesling', u'rigate', u'rigatoni', u'rind', u'rings', u'rins', u'rioja', u'ripe', u'ripened', u'rise', u'rising', u'riso', u'risotto', u'ritz', u'ro_tel', u'road', u'roast', u'roasted', u'roasting', u'robert', u'robiola', u'robusto', u'rock', u'rocket', u'rockfish', u'roe', u'roll', u'rolled', u'rolls', u'roma', u'romain', u'romaine', u'romana', u'romanesco', u'romano', u'rome', u'rooster', u'root', u'roots', u'roquefort', u'ros', u'rosa', u'rose', u'rosemari', u'rosemary', u'rosewater', u'rotel', u'rotelle', u'roti', u'rotini', u'rotisserie', u'roughy', u'rouille', u'round', u'rounds', u'roux', u'royal', u'rub', u'rubbed', u'ruby', u'rum', u'rump', u'runny', u'rusk', u'russet', u'russian', u'rustic', u'rutabaga', u'rye', u'saba', u'sablefish', u'sack', u'safflower', u'saffron', u'sage', u'sago', u'saigon', u'sake', u'saki', u'salad', u'salami', u'salata', u'salmon', u'salsa', u'salsify', u'salt', u'salted', u'saltine', u'saltines', u'saltpeter', u'sambal', u'sambuca', u'samphire', u'san', u'sanding', u'sandwich', u'sandwiches', u'sangiovese', u'sangria', u'sansho', u'santa', u'santo', u'sardi', u'sardines', u'sargento', u'sashimi', u'sato', u'satsuma', u'satsumas', u'sauc', u'sauce', u'sauces', u'sauerkraut', u'sausag', u'sausage', u'sausages', u'sauterne', u'sauvignon', u'savoiardi', u'savory', u'savoy', u'sazon', u'scallion', u'scallions', u'scallopini', u'scallops', u'scape', u'schmaltz', u'schnapps', u'scones', u'scotch', u'scrod', u'scrub', u'scrubbed', u'sea', u'seafood', u'seamless', u'season', u'seasoned', u'seasoning', u'seasons', u'seaweed', u'sec', u'seca', u'secret', u'secrets', u'sections', u'seed', u'seedless', u'seeds', u'segments', u'seitan', u'sel', u'self', u'self_rising', u'seltzer', u'semi', u'semi_soft', u'semi_sweet', u'semisweet', u'semolina', u'serrano', u'serving', u'sesame', u'sesame_ginger', u'seven', u'seville', u'shahi', u'shallots', u'shanghai', u'shank', u'shanks', u'shao', u'shaoxing', u'shapes', u'shark', u'sharp', u'shaved', u'shavings', u'sheeps', u'sheepshead', u'sheet', u'sheets', u'shell', u'shell_on', u'shelled', u'shellfish', u'shells', u'sherbet', u'sherry', u'shichimi', u'shiitake', u'shimeji', u'shin', u'shirataki', u'shiraz', u'shiro', u'shiromiso', u'shishito', u'shiso', u'shoepeg', u'shoga', u'shoots', u'short', u'short_grain', u'shortbread', u'shortcakes', u'shortcrust', u'shortening', u'shoulder', u'shoyu', u'shred', u'shredded', u'shrimp', u'shuck', u'shucked', u'shungiku', u'sichuan', u'sichuanese', u'sicilian', u'sides', u'silken', u'silver', u'simple', u'single', u'sirloin', u'siu', u'size', u'skate', u'skim', u'skimmed', u'skin', u'skinless', u'skinned', u'skins', u'skippy', u'skirt', u'slab', u'slaw', u'slice', u'sliced', u'slices', u'slider', u'slim', u'slivered', u'sloe', u'small', u'smart', u'smith', u'smithfield', u'smoke', u'smoked', u'smooth', u'snail', u'snails', u'snapper', u'snappers', u'snaps', u'snip', u'snow', u'soaking', u'soba', u'sobrasada', u'sockeye', u'soda', u'sodium', u'sofrito', u'soft', u'soft_boiled', u'soft_shell', u'soft_shelled', u'soft_wheat', u'soften', u'softened', u'soi', u'sole', u'solid', u'somen', u'sooji', u'soppressata', u'sorbet', u'sorghum', u'sorrel', u'souchong', u'soup', u'sour', u'sourdough', u'soursop', u'southern', u'southwest', u'soy', u'soy_based', u'soya', u'soybean', u'soybeans', u'soymilk', u'spaghetti', u'spaghettini', u'spam', u'spanish', u'spare', u'spareribs', u'sparkling', u'spearmint', u'spears', u'specials', u'speck', u'spelt', u'spice', u'spiced', u'spices', u'spicy', u'spike', u'spinach', u'spiny', u'spiral', u'splenda', u'split', u'sponge', u'sports', u'spot', u'spray', u'spread', u'spreadable', u'sprig', u'sprigs', u'spring', u'sprinkles', u'sprite', u'sprouts', u'spumante', u'squabs', u'squash', u'squeezed', u'squid', u'squirt', u'sriracha', u'st', u'standing', u'star', u'starch', u'starchy', u'starter', u'steak', u'steaks', u'steamed', u'steamer', u'steel_cut', u'stellette', u'stem', u'stems', u'stevia', u'stew', u'stewed', u'stewing', u'stick', u'stickers', u'sticks', u'sticky', u'stilton', u'stir', u'stock', u'stolichnaya', u'stone', u'stone_ground', u'stonefire', u'store', u'store_bought', u'stout', u'straight', u'strained', u'straw', u'strawberri', u'strawberries', u'strawberry', u'streaky', u'string', u'strip', u'striped', u'strips', u'strong', u'strozzapreti', u'stuffed', u'stuffing', u'sturgeon', u'style', u'sub', u'submarine', u'substitute', u'sucanat', u'success', u'suckling', u'sucralose', u'sucrolose', u'suet', u'sugar', u'sugarcane', u'sugars', u'sultana', u'sum', u'sumac', u'summer', u'sun', u'sun_dried', u'sunchokes', u'sundae', u'sundried', u'sunflower', u'superfine', u'superior', u'sushi', u'swanson', u'swede', u'sweet', u'sweetbreads', u'sweeten', u'sweetened', u'sweetener', u'sweeteners', u'swerve', u'swiss', u'swordfish', u'syd', u'syrup', u'szechuan', u'szechwan', u't_bone', u'tabasco', u'table', u'taco', u'tagliarini', u'tagliatelle', u'tahini', u'tail', u'tails', u'taiwanese', u'taleggio', u'tallow', u'tamale', u'tamales', u'tamari', u'tamarind', u'tandoori', u'tangelos', u'tangerine', u'tangzhong', u'tap', u'tapatio', u'tapenade', u'tapioca', u'tarama', u'taro', u'tarragon', u'tart', u'tartar', u'tartlet', u'tasso', u'taste', u'tater', u'tatsoi', u'tawny', u'tea', u'teardrop', u'teas', u'teff', u'teleme', u'tempeh', u'tempura', u'tender', u'tenderizer', u'tenderloin', u'tenderloins', u'tenders', u'tendons', u'tentacles', u'tequila', u'teriyaki', u'terrine', u'tex', u'tex_mex', u'texas', u'textured', u'thai', u'thaw', u'thawed', u'thick_cut', u'thickeners', u'thigh', u'thighs', u'thinli', u'thousand', u'thread', u'threads', u'thyme', u'ti', u'tiger', u'tikka', u'tilapia', u'tip', u'tipo', u'tips', u'toast', u'toasted', u'toasts', u'tobiko', u'toffee', u'tofu', u'togarashi', u'tokyo', u'tom', u'tomate', u'tomatillo', u'tomatillos', u'tomato', u'tomatoes', u'ton', u'tongue', u'tonic', u'tonkatsu', u'tony', u'toor', u'topping', u'toppings', u'tops', u'topside', u'torn', u'torpedo', u'tortellini', u'tortelloni', u'tortilla', u'tortillas', u'tostada', u'tostadas', u'tostitos', u'tots', u'touch', u'toulouse', u'tradicional', u'tradit', u'traditional', u'treacle', u'tree', u'treviso', u'tri', u'tri_tip', u'tricolor', u'tripe', u'triple', u'triscuits', u'tropic', u'tropical', u'trotters', u'trout', u'true', u'truffle', u'truffles', u'trumpet', u'truva', u'tsuyu', u'tuaca', u'tube', u'tubetti', u'tubettini', u'tumeric', u'tuna', u'tuong', u'tupelo', u'turbinado', u'turbot', u'turkei', u'turkey', u'turkish', u'turmeric', u'turnip', u'turnips', u'turtle', u'tuscan', u'tuttorosso', u'tvp', u'twists', u'tyson', u'tzatziki', u'udon', u'ulek', u'ume', u'umeboshi', u'unagi', u'unbaked', u'unbleached', u'uncle', u'uncook', u'uncooked', u'undiluted', u'undrain', u'unflavored', u'unhulled', u'uni', u'unsalt', u'unsalted', u'unseasoned', u'unsmoked', u'unsulphured', u'unsweeten', u'unsweetened', u'urad', u'usukuchi', u'vadouvan', u'val', u'valencia', u'valley', u'vanilla', u'varieti', u'varnish', u'vay', u'veal', u'vegan', u'veget', u'vegeta', u'vegetable', u'vegetable_filled', u'vegetables', u'vegetarian', u'veggie', u'veggies', u'velveeta', u'velvet', u'venison', u'vera', u'verbena', u'verde', u'veri', u'verjuice', u'verjus', u'vermicelli', u'vermouth', u'verts', u'viande', u'victoria', u'vidalia', u'vie', u'vietnamese', u'vin', u'vinaigrett', u'vinaigrette', u'vindaloo', u'vine', u'vinegar', u'vineyard', u'violets', u'virgin', u'virginia', u'vital', u'vitamin', u'vodka', u'wafer', u'wafers', u'waffle', u'wagon', u'wakame', u'walnut', u'walnuts', u'warm', u'wasabe', u'wasabi', u'water', u'watercress', u'watermelon', u'wax', u'waxy', u'wedge', u'wedges', u'weed', u'wensleydale', u'wesson', u'wheat', u'wheatberries', u'wheel', u'wheels', u'whey', u'whip', u'whipped', u'whipping', u'whiskey', u'whisky', u'white', u'whitefish', u'whites', u'whole_milk', u'wholemeal', u'wholesome', u'wide', u'wieners', u'wild', u'wildflower', u'williams', u'wine', u'winesap', u'wing', u'wingettes', u'wings', u'winter', u'wish', u'wish_bone', u'wok', u'woksaus', u'wolf', u'wolfberries', u'won', u'wondra', u'wonton', u'wood', u'woods', u'worcestershire', u'world', u'wrappers', u'wraps', u'xanthan', u'xuxu', u'yaki_nori', u'yakisoba', u'yam', u'yams', u'yardlong', u'yeast', u'yellow', u'yellowfin', u'yellowtail', u'yoghurt', u'yogurt', u'yolk', u'yolks', u'yoplait', u'york', u'young', u'yu', u'yuca', u'yucca', u'yukon', u'yum', u'yuzu', u'yuzukosho', u'zaatar', u'zatarains', u'zero', u'zest', u'zesty', u'zinfandel', u'ziti', u'zucchini']\n"
     ]
    }
   ],
   "source": [
    "print tfvect.get_feature_names()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see the words like \"banana\" and \"bananas\" show together, so we can use lemmatization to remove the redundant features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tokenize_and_lemmatizer(text):\n",
    "    tokens = word_tokenize(text)        \n",
    "    lemmas = [WordNetLemmatizer().lemmatize(t) for t in tokens]\n",
    "    return lemmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tfvect = TfidfVectorizer(stop_words='english',tokenizer=tokenize_and_lemmatizer)\n",
    "trainXtf = tfvect.fit_transform(trainRecipe)\n",
    "testXtf = tfvect.transform(testRecipe)\n",
    "logreg = linear_model.LogisticRegressionCV(Cs=logspace(1,10,10), cv=5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc of logistic regression =  0.853396691306\n"
     ]
    }
   ],
   "source": [
    "logreg.fit(trainXtf, trainY)\n",
    "\n",
    "predTrainYlr = logreg.predict(trainXtf)\n",
    "predTestYlr = logreg.predict(testXtf)\n",
    "\n",
    "print \"acc of logistic regression = \", mean(predTrainYlr == trainY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training accuracy is lower, however, the testing accuracy on Kaggle slightly increases to 78.982%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We only use single words as features, however, each ingredient contains at least one word. So we modify the preprocessing method to see the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "trainRecipe = []\n",
    "for li in traindata['data']:\n",
    "    s=\"\"\n",
    "    for x in li:\n",
    "        x=re.sub(' ','',x)\n",
    "        s += ' '+re.sub(r'[^a-zA-Z_ ]','',x) # keep the underscore\n",
    "    trainRecipe.append(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "testRecipe = []\n",
    "for li in testdata['data']:\n",
    "    s=\"\"\n",
    "    for x in li:\n",
    "        x=re.sub(' ','',x)\n",
    "        s += ' '+re.sub(r'[^a-zA-Z_ ]','',x) # keep the underscore\n",
    "    testRecipe.append(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " romainelettuce blackolives grapetomatoes garlic pepper purpleonion seasoning garbanzobeans fetacheesecrumbles\n"
     ]
    }
   ],
   "source": [
    "print trainRecipe[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It shows that we catenate the words in a single ingredient together so that the tokenizer will not split them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tfvect = TfidfVectorizer(stop_words='english',tokenizer=tokenize_and_lemmatizer)\n",
    "trainXtf = tfvect.fit_transform(trainRecipe)\n",
    "testXtf = tfvect.transform(testRecipe)\n",
    "logreg = linear_model.LogisticRegressionCV(Cs=logspace(1,10,10), cv=5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc of logistic regression =  0.900060340926\n"
     ]
    }
   ],
   "source": [
    "logreg.fit(trainXtf, trainY)\n",
    "\n",
    "predTrainYlr = logreg.predict(trainXtf)\n",
    "predTestYlr = logreg.predict(testXtf)\n",
    "\n",
    "print \"acc of logistic regression = \", mean(predTrainYlr == trainY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy of it in Kaggle is 78.831%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have also tried out difference feature extractions by setting different min_df and ngram_range. Min_df can restrict the less frequent features. Since ingredients have different lengths, the combined word can be meaningful. Therefore we can manipulate different ngram_range.\n",
    "\n",
    "(1). The tesing accuracy on Kaggle is 0.76016.\n",
    "\n",
    "tfvect = TfidfVectorizer(stop_words='english',ngram_range=(1,6), min_df = 0.00067, tokenizer=tokenize_and_lemmatizer)\n",
    "\n",
    "(2). Only set the min_df=0.001 for the features and the result on Kaggle is 0.78459.\n",
    "\n",
    "tfvect = TfidfVectorizer(stop_words='english',min_df = 0.001, tokenizer=tokenize_and_lemmatizer)\n",
    "\n",
    "(3). Only set the ngram_range(1,2) and the result on Kaggle is 0.78600.\n",
    "\n",
    "tfvect = TfidfVectorizer(stop_words='english',ngram_range=(1,2), tokenizer=tokenize_and_lemmatizer)\n",
    "\n",
    "The best result is still from the logistic regression using tf-idf with tokenize_and_lemmatizer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "write_csv_kaggle_cooking(\"kaggle_cooking_test.csv\", testdata[\"id\"], predTestYlr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "FURTHER THINKING\n",
    "\n",
    " Insight: some special ingredient can directly determine the cuisine\n",
    "\n",
    "           E.g Shanghai -> China, Kimchi -> Korea\n",
    "           \n",
    " For each cuisine, specific set of ingredients.\n",
    "\n",
    " How to predict cuisine separately and merge at the end?  Feature union and averaging model predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
